---
title: 'Advanced Time Series Analysis: Computer Exercise 4'
author: "Anders Launer Bæk (s160159)"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes: 
    - \usepackage{graphicx}
output:
  pdf_document: default
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = FALSE, 
                      include = TRUE,
                      warning = FALSE,
                      fig.width = 8, fig.height = 4,
                      fig.show='hold', fig.align='center',
                      
                      eval = TRUE, 
                      tidy = TRUE, 
                      dev = 'pdf', 
                      cache = TRUE, fig.pos = "th!")

kable_format <- list(small.mark = ",",
                     big.mark = ',',
                     decimal.mark = '.',
                     nsmall = 3,
                     digits = 3,
                     scientific = FALSE,
                     big.interval = 3L)

library(ggplot2)
library(akima)
library(dplyr)
theme_TS <- function(base_size = 9, base_family = "", face = "plain"){
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.background = element_blank(), 
          panel.border = element_blank(),
          panel.grid = element_blank(),
          axis.text = element_text(size = base_size, face = face, family = base_family),
          axis.title = element_text(size = base_size, face = face, family = base_family),
          legend.text = element_text(size = base_size, face = face, family = base_family))
}

# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


```

$f\left( x \right)=\beta_0+\beta_1x+\beta_2x^2+\beta_3x^3+\sum_{k=1}^Kb_k\left( x -\xi_k \right)^3 $
$K = 3$


$\sum_{i=1}^n\left\{ y_i - f\left( x_i \right)  \right\} ^2+\lambda  \int\left\{ f^{''}\left( x \right)  \right\} ^2 dx$

$f^{''}\left( x \right) = 2 \beta_2 + 6 \beta_3 x + 6 b_1 (x-\xi_1) + 6 b_2(x-\xi_2) + 6 b_3 (x-\xi_3)$

$\int  \left\{ f^{ '' }\left( x \right)  \right\} ^{ 2 }dx=\frac { 4\left( \beta _{ 2 }+3\left( -\left( b_2\xi _{ 2 } \right) -b_3\xi _{ 3 }+\beta _{ 3 }x+b_2x+b_3x+b_1\left( -\xi _{ 1 }+x \right)  \right)  \right) ^{ 3 } }{ 9\left( \beta _{ 3 }+b_1+b_2+b_3 \right)  } $

`r lambda`

```{r}

lambda <- 10
win_size <- 40
K <- 3 # knots
features <- 3 + 1 # cubic spine


D <- matrix(0, nrow = K + features, ncol = K + features)
diag(D)[(features+1):(K + features)] <- 1

f_spline <- function(x_vec, K) {
  win_size <- length(x_vec)
  #K_knots <- seq(min(x_vec), max(x_vec),length=K)
  C <- matrix(NA, nrow = win_size, ncol = K + features)
  # insert 
  C[, 1] <- 1
  C[, 2] <- x_vec
  C[, 3] <- x_vec^2
  C[, 4] <- x_vec^3
  for (ii in 1:K) {
    C[, ii+4] <- (x_vec - K_knots[ii])^3
  }
  # C[, 5] <- (x_vec - K_knots[1])^3
  # C[, 6] <- (x_vec - K_knots[2])^3
  # C[, 7] <- (x_vec - K_knots[3])^3
  #
  return(C)
}

# with a peicewise linear and asymmetric loss function
rho <- function(tau, r) {
  if (r >= 0) { return(tau * r) }
  else { return((1-tau) * r) }
}



loss <- function(par, model, tau) {
  # calculate residuals
  res <- model[["p"]] - rowSums(f_spline(x_vec = model[["p_est"]], K=K) %*% par)
  # peicewise linear and asymmetric loss function
  res <- sapply(1:length(res), function(ii) {
    rho(tau=tau, r = res[ii])
    })
  # calculate SE 
  SE <- res^2 
  # add penalty 
  PEN <- lambda * t(par) %*% D %*% par
  return(sum(SE + PEN))
}

#

X$p_est_25 <- NA
X$p_est_50 <- NA
X$p_est_75 <- NA
X$residual_1h <- NA
X$residual_2h <- NA
X$residual_3h <- NA

#
X_cap <- data.frame(matrix(NA, ncol = (K + features) * 3, nrow = nrow(X)))


colnames(X_cap) <- c(paste0("25_", c("beta0","beta1","beta2","beta3","b1","b2","b3")),
                     paste0("50_", c("beta0","beta1","beta2","beta3","b1","b2","b3")),
                     paste0("75_", c("beta0","beta1","beta2","beta3","b1","b2","b3")))

         
pre_quantile_plot <- function(model, qt = c(25,50,75)) {
  return(ggplot(model) +
  geom_point(aes(x=t,y=p, color = "Observation"), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_25, color = paste0(qt[1]," pct. quantile")), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_50, color = paste0(qt[2]," pct. quantile")), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_75, color = paste0(qt[3]," pct. quantile")), alpha = 1/2) +
  labs(y = "power [kW]", x = "date time", color = "") +
  theme_TS())
  }


par25 <- par50 <- par75 <- c(-0.086046514,-0.4869695,0.6381740,-0.2518905,
                             0.2404314,0.005618799,-0.0010847470)  # 
# par25 <- par50 <- par75 <- rnorm(K + features)

for (ii in 1:(nrow(X)-win_size)) {
  # extract window
  idx_win <- 1:nrow(X) %in% ii:(ii + win_size - 1)
  X_tmp <- subset(X, select = c("p","p_est"), subset = idx_win)
  #
  par25 <- optim(par = par25, fn = loss, model = X_tmp, tau = 0.25)$par
  par50 <- optim(par = par50, fn = loss, model = X_tmp, tau = 0.5)$par
  par75 <- optim(par = par75, fn = loss, model = X_tmp, tau = 0.75)$par
  #
  X_cap[ii, 1:length(par25)] <- par25
  X_cap[ii, (1+length(par50)):(2*length(par50))] <- par50
  X_cap[ii, (1+2*length(par75)):(3*length(par75))] <- par75

  X[["p_est_25"]][idx_win] <- rowSums(f_spline(x_vec = X_tmp[["p_est"]], K=K) %*% par25)
  X[["p_est_50"]][idx_win] <- rowSums(f_spline(x_vec = X_tmp[["p_est"]], K=K) %*% par50)
  X[["p_est_75"]][idx_win] <- rowSums(f_spline(x_vec = X_tmp[["p_est"]], K=K) %*% par75)
  
  if (ii == 50) { break }
}

idx <- !is.na(X$p) & !is.na(X$p_est_25) & !is.na(X$p_est_50) & !is.na(X$p_est_75)
pre_quantile_plot(X[idx, ])

X$residual_1h <- X[["p"]] - X[["p_est_50"]]
# X_cap[2:10,8:14]

qqnorm(X$residual_1h)
qqline(X$residual_1h)

```


Adaptive RLS
```{r}
X_1 <- subset(X, select = c("t", "p", "p_est", "T1"))
X_1$p_est[X_1$p_est < 0] <- 0

# # Spline 
# matrix(NA, nrow = win_size, ncol = K + features)
#   # insert
#   C[, 1] <- 1
#   C[, 2] <- x_vec
#   C[, 3] <- x_vec^2
#   C[, 4] <- x_vec^3
#   for (ii in 1:K) {
#     C[, ii+4] <- (x_vec - K_knots[ii])^3
#   }
# 
# K <- 3
# 
# matrix(c(1, X_1$p_est,X_1$p_est^2,4,5,6,7), nrow = win_size, ncol = K + features, byrow = T)

# with a peicewise linear and asymmetric loss function



spline_func <- function(x, K=3, x_l, x_u) {
  #return(matrix(c(1, x, x^2, x^3, (x-seq(x_l, x_u, length = K))^3), ncol=4+K))
  return(sum(c(1, x, x^2, x^3, (x-seq(x_l, x_u, length = K))^3)))
} 

ARLS <- function(x = cbind(X_1$p_est, X_1$p_est^2), Y = X_1$p, lambda = cbind(X_1$lambda, X_1$lambda), tau = 0.25) {
  # initial 
  P <- matrix(NA, ncol = dim(x)[2], nrow = dim(x)[1])
  K <- matrix(NA, ncol = dim(x)[2], nrow = dim(x)[1])
  Theta <- matrix(NA, ncol = dim(x)[2], nrow = dim(x)[1])
  P[1, ] <- x[1,]
  Theta[1, ] <- 1
  K[1, ] <- 1

  # apply filter
  for (t in 2:dim(x)[1]) {
    # K
    K[t, ] <- (P[t-1, ] * x[t,]) / (lambda[t, ] + t(x[t,]) * P[t-1,] * x[t,])
    # Theta
    Theta[t, ] <- Theta[t-1,] + K[t,] * (Y[t] - t(x[t,]) * Theta[t-1,])
    # qunatile regression
    #Theta[t] <- Theta[t-1] + K[t] * rho(tau = tau, (Y[t] - t(x[t]) %*% Theta[t-1]))
    # P
    P[t,] <- 1/lambda[t,] * (P[t-1,] - ((P[t-1,] * x[t,] * t(x[t,]) * P[t-1,]) / (lambda[t,] + t(x[t,]) * P[t-1,] * x[t,])))
    if (tt == 100) { break }
  }
  # return
  return(P)
}


ARLS(x = X_1$p_est, Y = X_1$p, lambda = X_1$lambda, tau = 0.5)


```


























### quantile regression
does not performace
```{r}

tau_in <- 0.25
#lambda_opt <- optimize(loss, c(0,1), Y = X_1$p, X = cbind(1, X_1$p_est), TAU = tau_in)$minimum
X_1$pred_025 <- ARLS(x = cbind(1, X_1$p_est), lambda = lambda_opt, tau = tau_in)

tau_in <- 0.5
#lambda_opt <- optimize(loss, c(0,1), Y = X_1$p, X = cbind(1, X_1$p_est), TAU = tau_in)$minimum
X_1$pred_050 <- ARLS(x = cbind(1, X_1$p_est), lambda = lambda_opt, tau = tau_in)

tau_in <- 0.75
#lambda_opt <- optimize(loss, c(0,1), Y = X_1$p, X = cbind(1, X_1$p_est), TAU = tau_in)$minimum
X_1$pred_075 <- ARLS(x = cbind(1, X_1$p_est), lambda = lambda_opt, tau = tau_in)


ggplot(X_1[1:600,]) +
  geom_line(aes(x = t, y = p, color = "p"), alpha = 1/2) +
  geom_line(aes(x = t, y = pred_050, color = "qt50"), alpha = 1/3) +
  geom_line(aes(x = t, y = pred_025, color = "qt25"), alpha = 1/4) +
  geom_line(aes(x = t, y = pred_075, color = "qt75"), alpha = 1/4) +
  labs(y = "power [kW]", x = "date time", color = paste0("Lambda: ", round(lambda_opt,4))) +
  theme_TS()
X_1$res_025 <- X_1$p - X_1$pred_025
X_1$res_050 <- X_1$p - X_1$pred_050
X_1$res_075 <- X_1$p - X_1$pred_075

```
dasd
```{r}
qqnorm(X_1$res_050)
qqline(X_1$res_050)

```







variable forgetting factor









```{r}
normalit<-function(m){
   (m - min(m))/(max(m)-min(m))
}


X_cap %>% na.omit() %>% 
    mutate_all(funs(normalit)) %>% 
  ggplot() +
  geom_point()


```















It is important to model the interdependence structure of the prediction errors.
```{r}



pre_quantile_plot <- function(date_start, date_end, qt = c(25,50,75)) {
  return(X %>% dplyr::filter(t > date_start & t < date_end) %>%
  ggplot() +
  geom_point(aes(x=t,y=p, color = "Observation"), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_25, color = paste0(qt[1],", ",qt[2]," and ", qt[3]," pct. quantile")), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_50, color = paste0(qt[1],", ",qt[2]," and ", qt[3]," pct. quantile")), alpha = 1/2) +
  geom_line(aes(x=t,y=p_est_75, color = paste0(qt[1],", ",qt[2]," and ", qt[3]," pct. quantile")), alpha = 1/2) +
  labs(y = "power [kW]", x = "date time", color = "") +
  theme_TS())
  }
# select range
pre_quantile_plot(date_start = NULL,
                  date_end = NULL)

```



Correlation structure of forecast errors
interdependence structure
```{r}
n <- 10
mat <- matrix(runif(n*n,-1,1), nrow = n, ncol = n)

plot_res_correlation <- function(matrix, label_name="Correlation structure", axis_name="Residuals"){
  # rshape
  matrix <- reshape2::melt(matrix)
  # return plot
  return(interp2xyz(interp(x=matrix$Var1, y=matrix$Var2, z=matrix$value, duplicate="mean"), data.frame=TRUE) %>%
           ggplot(aes(x = x, y = y, z = z, fill = z)) + 
           geom_tile() + 
           scale_fill_distiller(palette="Spectral", na.value="white", name=label_name) +
           labs(y = axis_name, x = axis_name, color = "") +
           theme_TS())
}


plot_res_correlation(mat)


```

The forecasting models must be adaptive (in order to taken changes of dust on blades, changes roughness, etc., into account).
Reliable estimates of the forecast accuracy is very important (check the reliability by eg. reliability diagrams).
Reliable probabilistic forecasts are important to gain the full economical value.
Use more than a single MET provider for delivering the input to the prediction tool
– this improves the accuracy of wind power forecasts with 10-15 pct. Estimates of the correlation in forecasts errors important.
Forecasts of ’cross dependencies’ between load, prices, wind and solar power are important.
Probabilistic forecasts are very important for asymmetric cost functions.





Now with variable forgeeting factor

### 

### Uncertainty Estimation
```{r}
smooth.spline
```



Maybe include temperature..



### Fine tune values of lambda

Table \ref{tab_3_qt_lambda} reports the optimized values of $\lambda$.
```{r}
# find lambda for each series
lambda_opt <- list()
lambda_opt$p_est_1 <- list()
lambda_opt$p_est_2 <- list()
lambda_opt$p_est_3 <- list()
# 1 hour ----
lambda_opt$p_est_1$qt05 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_1), Y_in=X$p, tau_in=0.05)$minimum
lambda_opt$p_est_1$qt25 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_1), Y_in=X$p, tau_in=0.25)$minimum
lambda_opt$p_est_1$qt50 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_1), Y_in=X$p, tau_in=0.5)$minimum
lambda_opt$p_est_1$qt75 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_1), Y_in=X$p, tau_in=0.75)$minimum
lambda_opt$p_est_1$qt95 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_1), Y_in=X$p, tau_in=0.95)$minimum
# 2 hour ----
lambda_opt$p_est_2$qt05 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_2), Y_in=X$p, tau_in=0.05)$minimum
lambda_opt$p_est_2$qt25 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_2), Y_in=X$p, tau_in=0.25)$minimum
lambda_opt$p_est_2$qt50 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_2), Y_in=X$p, tau_in=0.5)$minimum
lambda_opt$p_est_2$qt75 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_2), Y_in=X$p, tau_in=0.75)$minimum
lambda_opt$p_est_2$qt95 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_2), Y_in=X$p, tau_in=0.95)$minimum
# 3 hour ----
lambda_opt$p_est_3$qt05 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_3), Y_in=X$p, tau_in=0.05)$minimum
lambda_opt$p_est_3$qt25 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_3), Y_in=X$p, tau_in=0.25)$minimum
lambda_opt$p_est_3$qt50 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_3), Y_in=X$p, tau_in=0.5)$minimum
lambda_opt$p_est_3$qt75 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_3), Y_in=X$p, tau_in=0.75)$minimum
lambda_opt$p_est_3$qt95 <- optimize(loss_func, lower=0.85, upper=1, x_in=cbind(1, X$p_est_3), Y_in=X$p, tau_in=0.95)$minimum
```



```{r}
# table ----
df_lambda <- data.frame(matrix(NA, nrow = 3, ncol = 6))
df_lambda[1,] <- cbind("1H",
                   round(lambda_opt$p_est_1$qt05, 4),
                   round(lambda_opt$p_est_1$qt25, 4),
                   round(lambda_opt$p_est_1$qt50, 4),
                   round(lambda_opt$p_est_1$qt75, 4),
                   round(lambda_opt$p_est_1$qt95, 4))
df_lambda[2,] <- cbind("2H",
                   round(lambda_opt$p_est_2$qt05, 4),
                   round(lambda_opt$p_est_2$qt25, 4),
                   round(lambda_opt$p_est_2$qt50, 4),
                   round(lambda_opt$p_est_2$qt75, 4),
                   round(lambda_opt$p_est_2$qt95, 4))
df_lambda[3,] <- cbind("3H",
                   round(lambda_opt$p_est_3$qt05, 4),
                   round(lambda_opt$p_est_3$qt25, 4),
                   round(lambda_opt$p_est_3$qt50, 4),
                   round(lambda_opt$p_est_3$qt75, 4),
                   round(lambda_opt$p_est_3$qt95, 4))
colnames(df_lambda) <- c("Quantile (in %)","5","25","50","75","95")
knitr::kable(df_lambda, 
             caption = "\\label{tab_3_qt_lambda}Optimized values of lambda for the given quantile, 1, 2 and 3 hour predictions.",
             format.args = kable_format, 
             row.names = FALSE)
```



Update the series...


```{r}
# 1 hour ----
# 50
tmp <- ARLS(x=cbind(1, X$p_est_1), lambda=lambda_opt$p_est_1$qt50, PI=NULL, tau = 0.5)
# predictions
X$p_pred_1_qt_05 <- tmp$es
# residuals
X$p_res_1_qt_05 <- tmp$epsilon
# theta
X[,c("theta_1_alpha_qt_05","theta_1_beta_qt_05")] <- tmp$theta
# 25
tmp <- ARLS(x=cbind(1, X$p_est_1), lambda=lambda_opt$p_est_1$qt25, PI=NULL, tau = 0.25)
# predictions
X$p_pred_1_qt_025 <- tmp$es
# residuals
X$p_res_1_qt_025 <- tmp$epsilon
# theta
X[,c("theta_1_alpha_qt_025","theta_1_beta_qt_025")] <- tmp$theta
# 75
tmp <- ARLS(x=cbind(1, X$p_est_1), lambda=lambda_opt$p_est_1$qt75, PI=NULL, tau = 0.75)
# predictions
X$p_pred_1_qt_075 <- tmp$es
# residuals
X$p_res_1_qt_075 <- tmp$epsilon
# theta
X[,c("theta_1_alpha_qt_075","theta_1_beta_qt_075")] <- tmp$theta
# 95
tmp <- ARLS(x=cbind(1, X$p_est_1), lambda=lambda_opt$p_est_1$qt95, PI=NULL, tau = 0.95)
# predictions
X$p_pred_1_qt_095 <- tmp$es
# residuals
X$p_res_1_qt_095 <- tmp$epsilon
# theta
X[,c("theta_1_alpha_qt_095","theta_1_beta_qt_095")] <- tmp$theta
# 5
tmp <- ARLS(x=cbind(1, X$p_est_1), lambda=lambda_opt$p_est_1$qt05, PI=NULL, tau = 0.05)
# predictions
X$p_pred_1_qt_005 <- tmp$es
# residuals
X$p_res_1_qt_005 <- tmp$epsilon
# theta
X[,c("theta_1_alpha_qt_005","theta_1_beta_qt_005")] <- tmp$theta


# 2 hour ----
# 50
tmp <- ARLS(x=cbind(1, X$p_est_2), lambda=lambda_opt$p_est_2$qt50, PI=NULL, tau = 0.5)
# predictions
X$p_pred_2_qt_05 <- tmp$es
# residuals
X$p_res_2_qt_05 <- tmp$epsilon
# theta
X[,c("theta_2_alpha_qt_05","theta_2_beta_qt_05")] <- tmp$theta
# 25
tmp <- ARLS(x=cbind(1, X$p_est_2), lambda=lambda_opt$p_est_2$qt25, PI=NULL, tau = 0.25)
# predictions
X$p_pred_2_qt_025 <- tmp$es
# residuals
X$p_res_2_qt_025 <- tmp$epsilon
# theta
X[,c("theta_2_alpha_qt_025","theta_2_beta_qt_025")] <- tmp$theta
# 75
tmp <- ARLS(x=cbind(1, X$p_est_2), lambda=lambda_opt$p_est_2$qt75, PI=NULL, tau = 0.75)
# predictions
X$p_pred_2_qt_075 <- tmp$es
# residuals
X$p_res_2_qt_075 <- tmp$epsilon
# theta
X[,c("theta_2_alpha_qt_075","theta_2_beta_qt_075")] <- tmp$theta

# 3 hour ----
# 50
tmp <- ARLS(x=cbind(1, X$p_est_3), lambda=lambda_opt$p_est_3$qt50, PI=NULL, tau = 0.5)
# predictions
X$p_pred_3_qt_05 <- tmp$es
# residuals
X$p_res_3_qt_05 <- tmp$epsilon
# theta
X[,c("theta_3_alpha_qt_05","theta_3_beta_qt_05")] <- tmp$theta
# 25
tmp <- ARLS(x=cbind(1, X$p_est_3), lambda=lambda_opt$p_est_3$qt25, PI=NULL, tau = 0.25)
# predictions
X$p_pred_3_qt_025 <- tmp$es
# residuals
X$p_res_3_qt_025 <- tmp$epsilon
# theta
X[,c("theta_3_alpha_qt_025","theta_3_beta_qt_025")] <- tmp$theta
# 75
tmp <- ARLS(x=cbind(1, X$p_est_3), lambda=lambda_opt$p_est_3$qt75, PI=NULL, tau = 0.75)
# predictions
X$p_pred_3_qt_075 <- tmp$es
# residuals
X$p_res_3_qt_075 <- tmp$epsilon
# theta
X[,c("theta_3_alpha_qt_075","theta_3_beta_qt_075")] <- tmp$theta
```



```{r fig.cap="\\label{fig_3_5}"}
X %>%
  select(t,p,p_pred_1,p_pred_1_qt_05,p_pred_1_qt_025,p_pred_1_qt_075,p_pred_1_qt_005,p_pred_1_qt_095) %>%
  filter(t > start_per, t < end_per) %>%
  ggplot(aes(t)) + 
  geom_ribbon(aes(ymin=(p_pred_1_qt_005), ymax=(p_pred_1_qt_095),fill = "5%-95% QT"), alpha=1) +
  geom_ribbon(aes(ymin=(p_pred_1_qt_025), ymax=(p_pred_1_qt_075),fill = "25%-75% QT"), alpha=1) +
  scale_fill_manual("Bands",values=c("#999999","#E69F00")) +
  geom_line(aes(y=p, color="p"), alpha=1) +
  geom_line(aes(y=p_pred_1_qt_05, color="50% QT"), alpha=1) +
  labs(y="p [kW]", x="time date", color="") +
  theme_TS()
```


\newpage

### Analysis of the residuals
Figure \ref{fig_3_2_2} illustrates the residuals as function of time for the 1 hour predictions.
```{r fig.cap="\\label{fig_3_2_2}Residuals as function of time.", message=FALSE, warning=FALSE}
X %>% 
  select(t,p,p_pred_1_qt_05) %>%
  mutate(p_res_1 = p - p_pred_1_qt_05) %>%
ggplot() +
  geom_line(aes(x=t, y=p_res_1, color="res_1H"), alpha=1/3) +
  labs(y="power [kW]", x="date time", color="Residauls") +
  theme_TS()
```

\newpage

Figure \ref{fig_3_3_2} illustrates the distribution of the residuals. As ealier there are a negative shift in the residuals.
```{r fig.cap="\\label{fig_3_3_2}Histogram of the residuals.", message=FALSE, warning=FALSE}
X %>% 
  select(t,p,p_pred_1_qt_05) %>%
  mutate(p_res_1 = p - p_pred_1_qt_05) %>%
ggplot() +
  geom_histogram(aes(x=p_res_1, color="res_1H", y=..density..), alpha=1/2) +
  stat_function(fun=dnorm, args=list(mean=mean(X$p_res_1), sd=sd(X$p_res_1))) +
  labs(x="epsilon", y="frequency (in %)", color="Residauls") +
  theme_TS()
```


Figure \ref{fig_3_4_2} shows the cumulated periodogram of the residuals. The qq-plot is quiet similar to figure \ref{fig_2_12} where $\lambda=1$. There are still systematic behavoiur left in the residuals.

```{r, fig.cap="\\label{fig_3_4_2}Cumulated periodogram of the residuals."}
tmp_p_res_1 <- X %>% 
  mutate(p_res_1 = p - p_pred_1_qt_05) %>%
  select(p_res_1)
# plot ----
cpgram <- cpgram_func(tmp_p_res_1)
ggplot() +
  geom_point(data=cpgram$df, aes(x=x, y=y, color="cpgram"), alpha=1/2) +
  geom_segment(aes(x=cpgram$confi_upper[1],
                   y=cpgram$confi_upper[3],
                   xend=cpgram$confi_upper[2],
                   yend=cpgram$confi_upper[4], colour="95%CI"),
               alpha=1/2) +
  geom_segment(aes(x=cpgram$confi_lower[1],
                   y=cpgram$confi_lower[3],
                   xend=cpgram$confi_lower[2],
                   yend=cpgram$confi_lower[4], colour="95%CI"),
               alpha=1/2) +
  labs(x="frequency", y="", color="") +
  theme_TS()
```


\newpage

### Performance of quantiles with fine tuned values of lambda
table \ref{tab_3_performance_2}
```{r}
#
below_95 <- sum(X$p < X$p_pred_1_qt_095) / n * 100
below_75 <- sum(X$p < X$p_pred_1_qt_075) / n * 100
below_25 <- sum(X$p < X$p_pred_1_qt_025) / n * 100
below_05 <- sum(X$p < X$p_pred_1_qt_005) / n * 100
#
above_95 <- sum(X$p > X$p_pred_1_qt_095) / n * 100
above_75 <- sum(X$p > X$p_pred_1_qt_075) / n * 100
above_25 <- sum(X$p > X$p_pred_1_qt_025) / n * 100
above_05 <- sum(X$p > X$p_pred_1_qt_005) / n * 100
#
betwe_0595 <- sum((X$p <= X$p_pred_1_qt_095) & (X$p >= X$p_pred_1_qt_005)) / n * 100
betwe_2575 <- sum((X$p <= X$p_pred_1_qt_075) & (X$p >= X$p_pred_1_qt_025)) / n * 100

df_performance <- cbind(df_performance, 
                        rbind(below_95,below_75,below_25,below_05,
                              betwe_0595,betwe_2575,
                              above_95,above_75,above_25,above_05))
colnames(df_performance) <- c("Quantile (in %)","AQRLS (in %)","AQRLS FT (in %)")
knitr::kable(df_performance, 
             caption = "\\label{tab_3_performance_2}Precentage of the observations that are below, between and above the considered quantile intervals where lambda have been optimized.",
             format.args = kable_format, 
             row.names = FALSE)
```




<!--
## Describe the correlation in the residuals...
figure \ref{fig_3_5}
```{r, fig.cap="\\label{fig_3_5}Contour plot of the recorded data where NA have been excluded. The power curve is created based upon Ws1 and Wd1."}
tmp <- X$p_res_1_qt_05[1:100] %*% t(X$p_res_1_qt_05[1:100])
tmp <- cor(tmp)
tmp <- setNames(reshape2::melt(tmp), c('x', 'y', 'z'))
interp2xyz(interp(x=tmp$x, y=tmp$y, z=tmp$z, duplicate="mean"), data.frame=TRUE) %>%
  filter(!is.na(z)) %>%
  tbl_df() %>%
  ggplot(aes(x=x, y=y, z=z, fill=z)) + 
  geom_tile() + 
  geom_contour(color="white", alpha=0.5) + 
  scale_fill_distiller(palette="Spectral", na.value="white", name="Power [kW]") + 
  #scale_y_discrete(limits=y_ticks, labels=y_ticks_labels) +
  labs(y="Wind direction [deg]", x="Wind speed [m/s]", color="") +
  theme_TS()
```
-->






<!--
## variable forgetting
```{r, echo=TRUE}
ARLS_VFF <- function(x, Y=X$p, tau=NULL, PI=NULL) {
  # create matrices 
  R <- XX <- matrix(0, nrow=dim(x)[2], ncol=dim(x)[2])
  Theta <- matrix(0, ncol=1, nrow=dim(x)[2])
  theta_par <- matrix(NA, nrow=dim(x)[1], ncol=dim(x)[2])
  estimate <- epsilon <- lambda <- sd <-  rep(NA, dim(x)[1])
  # apply filter
  for (t in 1:dim(x)[1]) {
    # update X
    diag(XX) <- x[t, ]
    # make prediction for t | t-1 (for theta)
    estimate[t] <- diag(XX) %*% Theta
    # prediction error
    epsilon[t] <- Y[t] - estimate[t]
    # estimate of confidence intervals
    if (!is.null(PI)) { 
      if (t > dim(x)[2]) {
        sd2 <- epsilon[t]^2
        sd[t] <- qt(PI, t - dim(x)[2]) * sqrt(sd2)
      } else { sd[t] <- NA }
    }
    # update lambda
    if (t != 1) {
      lambda[t] <- epsilon[t]^2 / (diag((1 + t(XX) %*% solve(R) %*% XX)) %*% Theta)
    } else {
      lambda[t] <- 1 
    }
    # update theta for t | t
    R <- XX %*% t(XX) + lambda[t] * R
    # Theta with or without quantile regression 
    if (is.null(tau)) { 
      Theta <- Theta + solve(R) %*% XX %*% (Y[t] - t(XX) %*% Theta) 
    } else { 
      Theta <- Theta + solve(R) %*% XX %*% rho(tau=tau, r=(Y[t] - t(XX) %*% Theta))
      }
    # trace theta
    theta_par[t, ] <- Theta
  }
  # return
  return(list("es"=estimate,
              "sd"=sd,
              "theta"=as.data.frame(theta_par),
              "epsilon"=epsilon,
              "lambda"=lambda))
}
```

```{r}

#ARLS_VFF(x = cbind(1, X$p_est_1))



```

## Describe the correlation in the residuals...
figure \ref{fig_3_6}
```{r, fig.cap="\\label{fig_3_6}Contour plot of the recorded data where NA have been excluded. The power curve is created based upon Ws1 and Wd1."}
X %>%
  select(t,p,p_res_1, T1) %>%
  #filter(t > start_per, t < end_per) %>%
  ggplot() +
  geom_point(aes(x=T1, y=p, color="p"), alpha=1/3) +
  #geom_line(aes(x=t, y=theta_1_beta, color="beta"), alpha=1/3) +
  labs(y="p [kW]", x="temperature [K]", color="") +
  theme_TS()

cor(X$T1, X$p)
```


figure \ref{fig_3_7}
```{r, fig.cap="\\label{fig_3_7}Contour plot of the recorded data where NA have been excluded. The power curve is created based upon Ws1 and Wd1."}
X %>%
  select(t,p, T1) %>%
  mutate(t_hour = as.integer(substr(t, 12, 13))) %>%
  #filter(t > start_per, t < end_per) %>%
  ggplot() +
  geom_point(aes(x=t_hour, y=p, color="alpha"), alpha=1/3) +
  #geom_line(aes(x=t, y=theta_1_beta, color="beta"), alpha=1/3) +
  labs(y="Value", x="date time", color="Normalized thetas") +
  theme_TS()

cor(X$toy, X$p)
```


-->
